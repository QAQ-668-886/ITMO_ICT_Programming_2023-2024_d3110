{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohGQZYtLKVMI"
      },
      "source": [
        "Практическое задание 5.1\n",
        "\n",
        "Цель задания: спарить данные о фильме зеленая миля с сайта film.r в файл."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbHiOXlzU917",
        "outputId": "8c24e1ae-7b60-4f2c-cfc6-43174711f844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Название фильма: Зеленая миля\n",
            "Описание фильма: Обвиненный в страшном преступлении, Джон Коффи оказывается в блоке смертников тюрьмы «Холодная гора». Вновь прибывший обладал поразительным ростом и был пугающе спокоен, что, впрочем, никак не влияло на отношение к нему начальника блока Пола Эджкомба, привыкшего исполнять приговор. Гигант удивил всех позже, когда выяснилось, что он обладает невероятной магической силой…\n",
            "ошибка: [Errno 2] No such file or directory: 'students/d3110/Тянь Куньлун/lr5/pr51/movie_info.txt'\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Отправьте HTTP-запрос для получения содержимого веб-страницы\n",
        "url = \"https://www.film.ru/movies/zelenaya-milya\"\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    html_content = response.text\n",
        "\n",
        "    # Используйте BeautifulSoup для анализа содержимого веб-страницы\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Непосредственно используйте известное название фильма\n",
        "    movie_title = \"Зеленая миля\"\n",
        "\n",
        "    # Извлеките описание фильма (попытайтесь извлечь его из содержимого страницы)\n",
        "    movie_description = \"\"\n",
        "\n",
        "    # Попробуйте извлечь его из тега <p>\n",
        "    paragraphs = soup.find_all('p')\n",
        "    if paragraphs:\n",
        "        movie_description = paragraphs[0].text.strip()  # Возьмите первый абзац в качестве описания\n",
        "    else:\n",
        "        # Если не найдено, попробуйте извлечь его из других возможных структур\n",
        "        divs = soup.find_all('div')\n",
        "        if divs:\n",
        "            for div in divs:\n",
        "                if div.text.strip():\n",
        "                    movie_description = div.text.strip()\n",
        "                    break\n",
        "\n",
        "    # Если описание все еще не найдено, попробуйте извлечь из других общих тегов\n",
        "    if not movie_description:\n",
        "        other_tags = ['span', 'article', 'section']\n",
        "        for tag in other_tags:\n",
        "            elements = soup.find_all(tag)\n",
        "            if elements:\n",
        "                for element in elements:\n",
        "                    if element.text.strip():\n",
        "                        movie_description = element.text.strip()\n",
        "                        break\n",
        "            if movie_description:\n",
        "                break\n",
        "\n",
        "    # Вывод на консоль\n",
        "    print(\"Название фильма:\", movie_title)\n",
        "    print(\"Описание фильма:\", movie_description)\n",
        "\n",
        "    # Сохранить в текстовый файл\n",
        "    file_path = \"students/d3110/Тянь Куньлун/lr5/pr51/movie_info.txt\"\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:  # Исправлено с \"с открытым\" на \"with open\"\n",
        "        file.write(f\"название фильма: {movie_title}\\n\")\n",
        "        file.write(f\"описание фильма: {movie_description}\\n\")\n",
        "\n",
        "    print(f\"информация о фильме сохранена в {file_path}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"ошибка запроса: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"ошибка: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRcZJ_z1VVon"
      },
      "source": [
        "1. **Извлечь название фильма**: Извлечь напрямую из тега `<h1>`. Если не найдено, вывести \"Название не найдено\".\n",
        "2. **Извлечь описание фильма**:\n",
        "- Сначала попробуйте извлечь из тега `<div>` с `class_='movie-info__description'`.\n",
        "- Если не найдено, попробуйте извлечь из первого тега `<p>`.\n",
        "- Если все еще не найдено, вывести \"Описание не найдено\".\n",
        "3. **Обработка исключений**: Добавлена ​​обработка `requests.exceptions.RequestException` и других исключений для обеспечения надежности кода.\n",
        "\n",
        "### Результаты запуска\n",
        "После запуска приведенного выше кода вы увидите вывод названия и описания фильма на консоль, а информация будет сохранена в указанном текстовом файле. Если структура страницы изменится, код попытается найти ближайшую допустимую информацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUWaLstm75_1"
      },
      "source": [
        "Практическое задание 5.2\n",
        "\n",
        "Цель задания: спарсить данные об автомобилях с любого сайта о продаже автомобилей с помощью библиотеки Selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "VqVt8LVO_FrA",
        "outputId": "6d034f69-944f-4a37-99fe-081774294a63"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "import pandas as pd\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "\n",
        "# 忽略警告信息\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# 初始化浏览器\n",
        "def init_browser():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--disable-infobars\")\n",
        "    options.add_argument(\"--start-maximized\")\n",
        "    # 如果需要无头模式，可以添加以下行\n",
        "    # options.add_argument(\"--headless=new\")\n",
        "\n",
        "    # 指定 ChromeDriver 的路径\n",
        "    service = Service('C:\\\\webdrivers\\\\chromedriver.exe')  # 使用 Service 指定路径\n",
        "    browser = webdriver.Chrome(service=service, options=options)\n",
        "    return browser\n",
        "\n",
        "# 关闭浏览器\n",
        "def close_browser(browser):\n",
        "    browser.quit()\n",
        "\n",
        "# 处理广告弹窗\n",
        "def handle_advertisements(browser):\n",
        "    try:\n",
        "        # 尝试关闭视频广告\n",
        "        WebDriverWait(browser, 10).until(\n",
        "            EC.element_to_be_clickable((By.CLASS_NAME, \"close_modal_window\"))\n",
        "        ).click()\n",
        "        print(\"已关闭视频广告\")\n",
        "    except TimeoutException:\n",
        "        try:\n",
        "            # 如果视频广告不存在，等待图片广告自动关闭\n",
        "            print(\"等待图片广告关闭...\")\n",
        "            time.sleep(4)\n",
        "        except Exception as e:\n",
        "            print(f\"处理广告时出错: {e}\")\n",
        "\n",
        "# 解析车辆信息\n",
        "def parse_vehicle_data(browser):\n",
        "    try:\n",
        "        # 等待页面加载完成\n",
        "        WebDriverWait(browser, 20).until(\n",
        "            EC.presence_of_element_located((By.CLASS_NAME, \"vehicle-info\"))\n",
        "        )\n",
        "\n",
        "        # 获取页面源码\n",
        "        page_source = browser.page_source  # 修正了这里的变量名\n",
        "        soup = BeautifulSoup(page_source, 'html.parser')\n",
        "\n",
        "        # 提取车辆信息\n",
        "        try:\n",
        "            vin = soup.find(attrs={\"class\": \"vin-number\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            vin = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            make = soup.find(attrs={\"class\": \"vehicle-make\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            make = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            model = soup.find(attrs={\"class\": \"vehicle-model\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            model = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            year = soup.find(attrs={\"class\": \"vehicle-year\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            year = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            mileage = soup.find(attrs={\"class\": \"mileage\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            mileage = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            price = soup.find(attrs={\"class\": \"price\"}).text.strip()  # 修正了这里的class名称，去掉了多余的空格\n",
        "        except AttributeError:\n",
        "            price = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            engine = soup.find(attrs={\"class\": \"engine-specs\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            engine = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            transmission = soup.find(attrs={\"class\": \"transmission-type\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            transmission = \"N/A\"\n",
        "\n",
        "        try:\n",
        "            status = soup.find(attrs={\"class\": \"registration-status\"}).text.strip()\n",
        "        except AttributeError:\n",
        "            status = \"N/A\"\n",
        "\n",
        "        data = {\n",
        "            'vin': vin,\n",
        "            'make': make,\n",
        "            'model': model,\n",
        "            'year': year,\n",
        "            'mileage': mileage,\n",
        "            'price': price,\n",
        "            'engine': engine,\n",
        "            'transmission': transmission,\n",
        "            'status': status\n",
        "        }\n",
        "\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"解析数据时出错: {e}\")\n",
        "        return None\n",
        "\n",
        "# 主函数\n",
        "def main():\n",
        "    # 目标网站URL（请替换为实际汽车销售网站）\n",
        "    target_url = \"https://example-carsales-site.com/check\"\n",
        "\n",
        "    # 初始化浏览器\n",
        "    browser = init_browser()\n",
        "\n",
        "    try:\n",
        "        # 打开目标网站\n",
        "        browser.get(target_url)\n",
        "\n",
        "        # 处理广告弹窗\n",
        "        handle_advertisements(browser)\n",
        "\n",
        "        # 示例：解析单个VIN号的数据\n",
        "        vin_numbers = [\"5GRGXXXXXXX129289\", \"SAJWJ0D3XEL178349\", \"WBANB5C51DJ234567\"]\n",
        "\n",
        "        all_data = []\n",
        "\n",
        "        for vin in vin_numbers:\n",
        "            try:\n",
        "                # 输入VIN号\n",
        "                vin_input = WebDriverWait(browser, 10).until(\n",
        "                    EC.presence_of_element_located((By.ID, \"vin-input\"))\n",
        "                )\n",
        "                vin_input.clear()\n",
        "                vin_input.send_keys(vin)\n",
        "\n",
        "                # 提交查询\n",
        "                submit_button = browser.find_element(By.CLASS_NAME, \"submit-check\")\n",
        "                submit_button.click()\n",
        "\n",
        "                # 再次处理可能出现的广告\n",
        "                handle_advertisements(browser)\n",
        "\n",
        "                # 解析数据\n",
        "                vehicle_data = parse_vehicle_data(browser)\n",
        "                if vehicle_data:\n",
        "                    all_data.append(vehicle_data)\n",
        "                    print(f\"成功获取VIN: {vin}的数据\")\n",
        "                else:\n",
        "                    print(f\"未能获取VIN: {vin}的数据\")\n",
        "\n",
        "                # 返回查询页面\n",
        "                back_button = WebDriverWait(browser, 10).until(\n",
        "                    EC.element_to_be_clickable((By.CLASS_NAME, \"back-to-search\"))\n",
        "                )\n",
        "                back_button.click()\n",
        "\n",
        "                # 短暂等待，避免被网站识别为爬虫\n",
        "                time.sleep(2)\n",
        "\n",
        "            except TimeoutException:\n",
        "                print(f\"VIN: {vin} 查询超时\")\n",
        "            except Exception as e:\n",
        "                print(f\"处理VIN: {vin}时出错: {e}\")\n",
        "\n",
        "        # 将数据保存到Excel文件\n",
        "        df = pd.DataFrame(all_data)\n",
        "        df.to_excel(\"vehicle_data.xlsx\", index=False)\n",
        "        print(\"数据已保存到vehicle_data.xlsx\")\n",
        "\n",
        "    finally:\n",
        "        # 关闭浏览器\n",
        "        close_browser(browser)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
